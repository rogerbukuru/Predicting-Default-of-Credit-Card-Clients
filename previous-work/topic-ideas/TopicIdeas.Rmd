---
title: "Topic Ideas"
author: "Roger Bukuru"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

\newpage

We are tasked to perform topic idea analysis.
The aim is to obtain 2-3 sets of data, from a specific application area.
Using these data sets we will describe a research question and perform various explorartory data analysis techniques.
Upon completion of the above analysis, one data set will be selected in order to implement and analysis various multivariate statistics techniques within the application area of the said data set.

For this analysis we will be analysing 3 data within the following app

# Business: Online Retail Data

This Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011.The company mainly sells unique all-occasion gift-ware.
Many customers of the company are wholesalers.

## Research Question

1.  **What items can be recommended with a given item ?**

    -   What products are often purchased together ?
    -   Are there cross-selling oportunities that exists ?

<!-- -->

2.  **Wholesaler customer retention over time ?**

    -   Are the factors that contribute to possible customer churns ?

<!-- -->

3.  **Can wholesalers be grouped into various customer segements based on their purchasing patterns ?**

    -   What are the trends of top wholesalers, how can they be targeted more effectively ?

<!-- -->

4.  **What gifts were are sold the most ?**

    -   Top selling products ?
    -   Probability of selling x product ?
    -   Identify relationships between the sales of different products ?
    -   What was the average basket size ?

## Exploratory Data Analysis

```{r, echo = FALSE, include=FALSE}
rm(list=ls())

library(readxl)
library(tidyverse)
library(knitr)
library(ggplot2)
library(dplyr)

```

```{r, echo = FALSE}
file_path = "../Data/Assignment/online_retail_II.xlsx"
online_retail_data = as_tibble(read_excel(file_path))
```

There are 4631 unique gift-ware items, the top 20 selling items are as shown below.
Gift ware with stock code 85123A was the highest selling item.
Across the 2 year period, there was a total of 28816 sales across 4384 wholesalers, about 5229 sales(invoices) do not have associated customers.

```{r, echo=FALSE}
# Explore the number of unique gift-sets and their popularity

# Total count of each item sold

gift_purchase_total_sold = online_retail_data %>% 
                         group_by(StockCode) %>%
                         summarise(`Total Sold` = sum(Quantity))
                      
              

top_20_selling_gifts = gift_purchase_total_sold %>%
                       arrange(desc(`Total Sold`)) %>%
                       head(n = 20)  
  
invoice_per_wholesaler = online_retail_data %>% 
                       group_by(Invoice, `Customer ID`) %>%
                       summarise(items_on_invoice = n(), .groups = 'drop')

invoices_without_customerIDs = invoice_per_wholesaler %>%
                              filter(is.na(`Customer ID`))

total_customers = unique(online_retail_data$`Customer ID`)

  
#highest_selling_items_percentage = top_20_selling_gifts$total[1]/count(online_retail_data)*100


# Plot the bar chart
ggplot(top_20_selling_gifts, aes(x = `Total Sold` , y =  reorder(StockCode, `Total Sold`), fill = StockCode)) +
  geom_bar(stat = "identity", fill = "brown") +
  theme_minimal() +
  labs(title = "Top 20 Giftwares Sold", x = "Total Sold", y = "Stock Code") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability

top_20_selling_gifts$StockCode[]

top_product_name = online_retail_data %>%
                   filter(StockCode == top_20_selling_gifts$StockCode[1]) %>%
                   select(Description) %>%
                   distinct(Description)


```

The top wholesalers

```{r, echo = FALSE}

unique_customers = online_retail_data %>%
                   distinct(`Customer ID`)

customer_country_distribution = online_retail_data %>%
                                  distinct(`Customer ID`, .keep_all = TRUE) %>%
                                  group_by(Country) %>%
                                  summarise(`Total Customers` = n()) %>%
                                  arrange(desc(`Total Customers`)) %>%
                                  head(n=5)

ggplot(customer_country_distribution, aes(x = `Total Customers` , y =  reorder(`Country`, `Total Customers`), fill = `Country`)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(title = "Customer Regions", x = "Total Customers", y = "Country") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability                          
                                  
customer_stats = online_retail_data %>% 
                 group_by(`Customer ID`) %>%
                 summarise(
                   `Total Invoices` = n_distinct(Invoice),
                   `Total Units Purchased` = sum(Quantity),
                   `Total Spend` = sum(Quantity * Price),
                 ) %>%
                arrange(desc(`Total Spend`)) %>%
                head(n=20)

na_customer_stats = online_retail_data %>% 
                 group_by(`Customer ID`) %>%
                 summarise(
                   `Total Invoices` = n_distinct(Invoice),
                   `Total Units Purchased` = sum(Quantity),
                    `Total Spend` = sum(Quantity * Price),
                 ) %>%
                arrange(desc(`Total Spend`)) %>%
                filter(is.na(`Customer ID`))
               # head(n=20)

customer_stats$`Customer ID`[1] = "Unknown"

kable(customer_stats)
top_wholesaler_revenue_contribution = customer_stats$`Total Spend`[1]/sum(customer_stats$`Total Spend`)*100

# Plot the bar chart
ggplot(customer_stats, aes(x = `Total Spend` , y =  reorder(`Customer ID`, `Total Spend`), fill = `Customer ID`)) +
  geom_bar(stat = "identity", fill = "#FF8C00") +
  theme_minimal() +
  labs(title = "Top 20 Revenue Generating Customers", x = "Revenue Generated", y = "Customer Id") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability
 
  
```

As seen in the table, it's worrying that the top performing wholesaler is unknown as they contribute to about 71.78% of the total revenue generated over the 2 year period.
This might be one or more different wholesalers.

# E-Commerce: Amazon Sale Data

This dataset provides an in-depth look at the profitability of e-commerce sales.
It contains data on a variety of sales channels, including Shiprocket and INCREFF, as well as financial information on related expenses and profits.
The columns contain data such as SKU codes, design numbers, stock levels, product categories, sizes and colors.
In addition to this we have included the MRPs across multiple stores like Ajio MRP , Amazon MRP , Amazon FBA MRP , Flipkart MRP , Limeroad MRP Myntra MRP and PaytmMRP along with other key parameters like amount paid by customer for the purchase , rate per piece for every individual transaction Also we have added transactional parameters like Date of sale months category fulfilledby B2b Status Qty Currency Gross amt .
This is a must-have dataset for anyone trying to uncover the profitability of e-commerce sales in today's marketplace

```{r}
rm(list=ls())

library(readxl)
library(tidyverse)
library(knitr)
library(ggplot2)
library(dplyr)

file_path = "../Data/Assignment/Amazon Sale Report.csv"
amazon_sales_report = as_tibble(read_csv(file_path))
```

# Research Questions

For the Amazon sales report data, we wish to explore which the various customer profiles \beging{itemize}

\item

W \\end{itemize} - Customer Segementation, what are various customer profiles - Product Recommendation: Which products can be recommended together ?
- What are the top predictors for a sale to be fulfilled ?

# Exploratry Data Analysis

The data consists of 20 variables, the variables are as described below.
It describes sales data from

## Feature Exploration

```{r, echo = FALSE}
colnames(amazon_sales_report)
sale_date_range = range(amazon_sales_report$Date)
sale_date_range
```

```{r, echo = FALSE}
total_unique_orders = amazon_sales_report |>
                      distinct(`Order ID`) |>
                      nrow()

                      
```

## Five number summary basket sizes

```{r, echo = FALSE}
basket_size = range(amazon_sales_report$Qty)
average_basket_szie = mean(amazon_sales_report$Qty)

minimum = min(amazon_sales_report$Qty)
first_quantile = quantile(amazon_sales_report$Qty, 0.25)
median_point = quantile(amazon_sales_report$Qty, 0.50)
third_quantile = quantile(amazon_sales_report$Qty, 0.75)
maximum = max(amazon_sales_report$Qty)

minimum
first_quantile
median_point
third_quantile
maximum

ggplot(amazon_sales_report, aes(x="", y=Qty)) +
  geom_boxplot(fill="lightblue", color="black") +
  labs(title="Box and Whisker Plot of Basket Sizes", x="", y="Basket Size") +
  theme_minimal()
```

-   Orders range from 0 to 15 units, with the average basket size consisting of 1 unit
-   The smallest quantity ordered in an any transaction is zero, this be be indicative of orders that were cancelled after having been placed.
-   The first quantile is 1 indicating that 25% of transactions have a basket size of 1 or less.
-   The median basket size is 1, indicating that half of the transactions have a single item
-   The third quantile also values matches that of the first quartile, 1, indicating that 75% of transactions have a single item,this shows that a very large majority of transactions consisted of a single item
-   The largest quantity in a single transaction is 15. Given the high frequency of single item transactions, this is indicative of an outlier(s).

## Transaction Amount

```{r, echo = FALSE}

no_na_amounts =  amazon_sales_report |>
                 drop_na(Amount) |>
                 select(Amount)


amount_range = range(no_na_amounts)
average_transaction_size = mean(no_na_amounts)

ggplot(no_na_amounts, aes(x=Amount)) +
  geom_histogram(aes(y=..density..), binwidth=100, fill="green", color="black") +
  geom_density(alpha=.2, fill="#FF6666") +
  labs(title="Distribution of Transaction Amounts", x="Transaction Amount", y="Density") +
  theme_minimal()

```

-   Transaction amounts from 0 to 5584, this indicates that there was a wide range of product prices.
-   The average transaction amount was 648.56 INR
-   In figure 1 we plot we show the frequency of different transaction amounts, with an estimated distribution overlayed. The distribution of transaction amounts is right-skewed, meaning that most transactions are of a relatively low value, with few high-value transactions.

## Order distribution and successful orders ?

```{r, echo=FALSE}
ship_postal_code = amazon_sales_report$`ship-postal-code`
distribtion_range = range(ship_postal_code[is.na(ship_postal_code)==FALSE])

ship_channels = amazon_sales_report |>
                distinct(`Sales Channel`)

order_statuses = amazon_sales_report |>
                 distinct(Status)
                 

amazon_completed_sales = amazon_sales_report |>
                        filter(Status == as.vector(order_statuses$Status)[2]) |>
                        distinct(`Order ID`, .keep_all = TRUE)

percentage_completed_sales = nrow(amazon_completed_sales)/total_unique_orders*100

```

-   We note the postal codes ranges from 110001 to 989898, indicating nationwide coverage across India.
-   There are 2 ship channels namely Amazon.in and Non-Amazon.
-   Order lifecyle consists of the following statuses
-   About 22.06% of the total sales can be identified with the "" status, indicating that this orders have been successfully sold.

# Business: Default of credit card clients

Additional Information

This research aimed at the case of customers' default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods.
From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients.
Because the real probability of default is unknown, this study presented the novel Sorting Smoothing Method to estimate the real probability of default.
With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one.
Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.

This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable.
This study reviewed the literature and used the following 23 variables as explanatory variables: X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.
X2: Gender (1 = male; 2 = female).
X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).
X4: Marital status (1 = married; 2 = single; 3 = others).
X5: Age (year).
X6 - X11: History of past payment.
We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; .
. .;X11 = the repayment status in April, 2005.
The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; .
. .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.
X12-X17: Amount of bill statement (NT dollar).
X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; .
. .; X17 = amount of bill statement in April, 2005.
X18-X23: Amount of previous payment (NT dollar).
X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; .
. .;X23 = amount paid in April, 2005.

<https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients>

## Research Questions

For our second data set we wish to explore what factors are more likely to effect a customer default e.g are younger customers more likely to default then older clients.
With this ability the bank would be able to more effectively cluster various customer risk profiles.

1.  Probability of customer defaulting

2.  What other factors are more likely to effect a customer defaulting i.e do younger customers default more then older clients ?

## Exploratory Data Analysis

```{r, echo = FALSE}
rm(list = ls())
library(readxl)
library(tidyverse)
library(knitr)
library(ggplot2)
library(dplyr)

file_path = "../../../Data/Assignment/default of credit card clients.xls"

credit_default_data = as_tibble(read_xls(file_path))

colnames(credit_default_data) = as.character(credit_default_data[1, ])
                                
credit_default_data = credit_default_data[-1,]


limit_balances  = credit_default_data |>
                  drop_na(LIMIT_BAL) |>
                  select(LIMIT_BAL) |>
                  as.matrix() |>
                  as.vector() |>
                  as.numeric()

colnames(credit_default_data)
average_limit_balance = mean(limit_balances)
range(limit_balances)

male_average_credit_limit = credit_default_data |>
                            filter(SEX == 1) |>
                            select(LIMIT_BAL) |>
                            as.matrix() |>
                            as.vector() |>
                            as.numeric() |>
                            mean()

female_average_credit_limit = credit_default_data |>
                            filter(SEX == 2) |>
                            select(LIMIT_BAL) |>
                            as.matrix() |>
                            as.vector() |>
                            as.numeric() |>
                            mean()

minimum = min(limit_balances)
first_quantile = quantile(limit_balances, 0.25)
median_point = quantile(limit_balances, 0.50)
third_quantile = quantile(limit_balances, 0.75)
maximum = max(limit_balances)

ggplot(credit_default_data, aes(x="", y=limit_balances)) +
  geom_boxplot(fill="lightblue", color="black") +
  labs(title="Credit Limit Five Number Summary", x="", y="Credit Limit") +
  theme_minimal()
```

-   The average credit limit amount is 167484.32
-   Credits limits range from 10 000 to 1000 000
-   Average male credit limit is 163519.82 and female is 170086.46

## Credit Utilization Patterns

```{r, echo = FALSE}
credit_spending = credit_default_data %>%
                  select(LIMIT_BAL, BILL_AMT1) %>%
                  mutate(across(everything(), as.numeric)) %>%
                  mutate(`Credit Utilization` = BILL_AMT1) %>%
                  ungroup()
credit_spending = credit_spending %>%
                  mutate(`Percentage Utilized`= round((`Credit Utilization`/LIMIT_BAL)*100,2))


ggplot(credit_spending, aes(x = `Percentage Utilized`)) +
  geom_histogram(aes(y=..density..),binwidth = 5, # Adjust binwidth based on your data's distribution and scale
                 fill = "steelblue", color = "black") +
  xlim(0, 200)+
  labs(title = "Distribution of Credit Utilization",
       x = "Credit Utilization (%)",
       y = "# of Customers") +
  theme_minimal() 

```

## Payment Patterns

```{r, echo = FALSE}
client_payments = credit_default_data %>%
                  select(LIMIT_BAL, PAY_AMT1, PAY_AMT2, PAY_AMT3, PAY_AMT4, PAY_AMT5, PAY_AMT6) %>%
                  mutate(across(everything(), as.numeric)) %>%
                  rowwise() %>%
                  mutate(`Total Payments` = sum(c_across(PAY_AMT1:PAY_AMT6), na.rm = TRUE)) %>%
                  ungroup()


outstanding_and_paid = data.frame(credit_spending$LIMIT_BAL, credit_spending$`Credit Utilization`, client_payments$`Total Payments`) |> 
  as.tibble()

colnames(outstanding_and_paid) = c("LIMIT_BAL", "Total Outstanding", "Total Payments")
outstanding_and_paid = outstanding_and_paid %>%
                       mutate(`Percentage Paid` = round((`Total Payments`/`Total Outstanding`)*100,2))

category =c("Total Outstanding", "Total Payments")

ggplot(client_payments, aes(x = `Total Payments`)) +
  geom_histogram(binwidth = 50000, # Adjust binwidth based on your data's distribution and scale
                 fill = "blue", color = "black") +
  labs(title = "Histogram of Total Payments",
       x = "Total Paymebts",
       y = "# of Customers") +
  theme_minimal() 
```

-   Above we show the distribution of the credit utilization from April to Septemner. It's right skewed indicating that most clients tend to use a small portion of their allocoated credit limit

## Response Variable Anaylysi

```{r, echo = FALSE}

response_variable = as.numeric(credit_default_data$`default payment next month`) %>%
                    as.tibble() %>%
                    rename(., Class = value)


default_yes = response_variable %>%
              filter(Class == 1)


default_no =  response_variable %>%
              filter(Class == 0)

agg_data = response_variable %>%
           group_by(Class) %>%
           summarise(Count = n()) %>%
           mutate(Percentage = Count /sum(Count) *100)

percentage_yes = nrow(default_yes)/nrow(credit_default_data) *100
percentage_no = nrow(default_no)/nrow(credit_default_data) *100  

ggplot(agg_data, aes(x = factor(Class, labels = c("No", "Yes")), y = Count, fill = factor(Class, labels = c("No", "Yes")))) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), vjust = -0.5) +
  labs(x = "Default payment next month", y = "Number of Clients", title = "Class Distribution") +
  scale_fill_manual(values = c("No" = "darkgreen", "Yes" = "red")) +  # Customize bar colors
  theme_minimal()+
  theme(legend.position = "none")  # Remove the legend

```
